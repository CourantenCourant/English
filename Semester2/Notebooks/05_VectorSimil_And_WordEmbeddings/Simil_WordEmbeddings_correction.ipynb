{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18137746-fdb4-41bf-bf69-f5d1b0ce1b84",
   "metadata": {},
   "source": [
    "cf. the lab from the [course](https://www.coursera.org/learn/classification-vector-spaces-in-nlp) for more details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6230eedf-196c-45a9-94fc-a0997c90d12d",
   "metadata": {},
   "source": [
    "# Manipulating Word Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ca78be-5d5b-492b-be93-deaf4a02fe31",
   "metadata": {},
   "source": [
    "The goal of this lab is to us pre-trained word vectors to predict relationships betwen words, using cosine similarity and euclidian distance as similarity metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a78e54b-d9df-4056-bb9e-b7358f9776ca",
   "metadata": {},
   "source": [
    "## Loading pretrained vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a10ee19-5809-4ea3-8d3d-12533ede3052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "243"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import pickle\n",
    "import pprint as pp\n",
    "\n",
    "# Load pre-trained embeddings\n",
    "word_embeddings = pickle.load( open( \"word_embeddings_subset.p\", \"rb\" ) )\n",
    "len(word_embeddings) # there should be 243 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cf48077-6a9a-44b2-9a70-8932142486ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abuja\n",
      "Accra\n",
      "Afghanistan\n",
      "Albania\n",
      "Algeria\n",
      "Algiers\n",
      "Amman\n",
      "Angola\n",
      "Ankara\n",
      "Antananarivo\n",
      "Apia\n",
      "Armenia\n",
      "Ashgabat\n",
      "Asmara\n",
      "Astana\n",
      "Athens\n",
      "Australia\n",
      "Austria\n",
      "Azerbaijan\n",
      "Baghdad\n",
      "Bahamas\n",
      "Bahrain\n",
      "Baku\n",
      "Bamako\n",
      "Bangkok\n",
      "Bangladesh\n",
      "Banjul\n",
      "Beijing\n",
      "Beirut\n",
      "Belarus\n",
      "Belgium\n",
      "Belgrade\n",
      "Belize\n",
      "Belmopan\n",
      "Berlin\n",
      "Bern\n",
      "Bishkek\n",
      "Botswana\n",
      "Bratislava\n",
      "Brussels\n",
      "Bucharest\n",
      "Budapest\n",
      "Bujumbura\n",
      "Bulgaria\n",
      "Burundi\n",
      "Cairo\n",
      "Canada\n",
      "Canberra\n",
      "Caracas\n",
      "Chile\n",
      "China\n",
      "Chisinau\n",
      "Conakry\n",
      "Copenhagen\n",
      "Croatia\n",
      "Cuba\n",
      "Cyprus\n",
      "Dakar\n",
      "Damascus\n",
      "Denmark\n",
      "Dhaka\n",
      "Doha\n",
      "Dominica\n",
      "Dublin\n",
      "Dushanbe\n",
      "Ecuador\n",
      "Egypt\n",
      "England\n",
      "Eritrea\n",
      "Estonia\n",
      "Fiji\n",
      "Finland\n",
      "France\n",
      "Funafuti\n",
      "Gabon\n",
      "Gaborone\n",
      "Gambia\n",
      "Georgetown\n",
      "Georgia\n",
      "Germany\n",
      "Ghana\n",
      "Greece\n",
      "Greenland\n",
      "Guinea\n",
      "Guyana\n",
      "Hanoi\n",
      "Harare\n",
      "Havana\n",
      "Helsinki\n",
      "Honduras\n",
      "Hungary\n",
      "Indonesia\n",
      "Iran\n",
      "Iraq\n",
      "Ireland\n",
      "Islamabad\n",
      "Italy\n",
      "Jakarta\n",
      "Jamaica\n",
      "Japan\n",
      "Jordan\n",
      "Kabul\n",
      "Kampala\n",
      "Kathmandu\n",
      "Kazakhstan\n",
      "Kenya\n",
      "Khartoum\n",
      "Kiev\n",
      "Kigali\n",
      "Kingston\n",
      "Kyrgyzstan\n",
      "Laos\n",
      "Latvia\n",
      "Lebanon\n",
      "Liberia\n",
      "Libreville\n",
      "Libya\n",
      "Liechtenstein\n",
      "Lilongwe\n",
      "Lima\n",
      "Lisbon\n",
      "Lithuania\n",
      "Ljubljana\n",
      "London\n",
      "Luanda\n",
      "Lusaka\n",
      "Macedonia\n",
      "Madagascar\n",
      "Madrid\n",
      "Malawi\n",
      "Mali\n",
      "Malta\n",
      "Managua\n",
      "Manama\n",
      "Manila\n",
      "Maputo\n",
      "Mauritania\n",
      "Minsk\n",
      "Mogadishu\n",
      "Moldova\n",
      "Monrovia\n",
      "Montenegro\n",
      "Montevideo\n",
      "Morocco\n",
      "Moscow\n",
      "Mozambique\n",
      "Muscat\n",
      "Nairobi\n",
      "Namibia\n",
      "Nassau\n",
      "Nepal\n",
      "Niamey\n",
      "Nicaragua\n",
      "Nicosia\n",
      "Niger\n",
      "Nigeria\n",
      "Norway\n",
      "Nouakchott\n",
      "Nuuk\n",
      "Oman\n",
      "Oslo\n",
      "Ottawa\n",
      "Pakistan\n",
      "Paramaribo\n",
      "Paris\n",
      "Peru\n",
      "Philippines\n",
      "Podgorica\n",
      "Poland\n",
      "Portugal\n",
      "Qatar\n",
      "Quito\n",
      "Rabat\n",
      "Riga\n",
      "Romania\n",
      "Rome\n",
      "Roseau\n",
      "Russia\n",
      "Rwanda\n",
      "Samoa\n",
      "Santiago\n",
      "Senegal\n",
      "Serbia\n",
      "Skopje\n",
      "Slovakia\n",
      "Slovenia\n",
      "Sofia\n",
      "Somalia\n",
      "Spain\n",
      "Stockholm\n",
      "Sudan\n",
      "Suriname\n",
      "Suva\n",
      "Sweden\n",
      "Switzerland\n",
      "Syria\n",
      "Taipei\n",
      "Taiwan\n",
      "Tajikistan\n",
      "Tallinn\n",
      "Tashkent\n",
      "Tbilisi\n",
      "Tegucigalpa\n",
      "Tehran\n",
      "Thailand\n",
      "Tirana\n",
      "Tokyo\n",
      "Tripoli\n",
      "Tunis\n",
      "Tunisia\n",
      "Turkey\n",
      "Turkmenistan\n",
      "Tuvalu\n",
      "Uganda\n",
      "Ukraine\n",
      "Uruguay\n",
      "Uzbekistan\n",
      "Vaduz\n",
      "Valletta\n",
      "Venezuela\n",
      "Vienna\n",
      "Vientiane\n",
      "Vietnam\n",
      "Vilnius\n",
      "Warsaw\n",
      "Windhoek\n",
      "Yerevan\n",
      "Zagreb\n",
      "Zambia\n",
      "Zimbabwe\n",
      "city\n",
      "continent\n",
      "country\n",
      "gas\n",
      "happy\n",
      "joyful\n",
      "king\n",
      "oil\n",
      "petroleum\n",
      "queen\n",
      "sad\n",
      "town\n",
      "village\n"
     ]
    }
   ],
   "source": [
    "# see which words are in the vocab\n",
    "for key in sorted(word_embeddings.keys()):\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76169e90-5ce4-4064-9405-1419048a2b56",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[-0.08007812  0.13378906  0.14355469  0.09472656 -0.04736328 -0.02355957\n",
      " -0.00854492 -0.18652344  0.04589844 -0.08154297 -0.03442383 -0.11621094\n",
      "  0.21777344 -0.10351562 -0.06689453  0.15332031 -0.19335938  0.26367188\n",
      " -0.13671875 -0.05566406  0.07470703 -0.00070953  0.09375    -0.14453125\n",
      "  0.04296875 -0.01916504 -0.22558594 -0.12695312 -0.0168457   0.05224609\n",
      "  0.0625     -0.1484375  -0.01965332  0.17578125  0.10644531 -0.04760742\n",
      " -0.10253906 -0.28515625  0.10351562  0.20800781 -0.07617188 -0.04345703\n",
      "  0.08642578  0.08740234  0.11767578  0.20996094 -0.07275391  0.1640625\n",
      " -0.01135254  0.0025177   0.05810547 -0.03222656  0.06884766  0.046875\n",
      "  0.10107422  0.02148438 -0.16210938  0.07128906 -0.16210938  0.05981445\n",
      "  0.05102539 -0.05566406  0.06787109 -0.03759766  0.04345703 -0.03173828\n",
      " -0.03417969 -0.01116943  0.06201172 -0.08007812 -0.14941406  0.11914062\n",
      "  0.02575684  0.00302124  0.04711914 -0.17773438  0.04101562  0.05541992\n",
      "  0.00598145  0.03027344 -0.07666016 -0.109375    0.02832031 -0.10498047\n",
      "  0.0100708  -0.03149414 -0.22363281 -0.03125    -0.01147461  0.17285156\n",
      "  0.08056641 -0.10888672 -0.09570312 -0.21777344 -0.07910156 -0.10009766\n",
      "  0.06396484 -0.11962891  0.18652344 -0.02062988 -0.02172852  0.29296875\n",
      " -0.00793457  0.0324707  -0.15136719  0.00227356 -0.03540039 -0.13378906\n",
      "  0.0546875  -0.03271484 -0.01855469 -0.10302734 -0.13378906  0.11425781\n",
      "  0.16699219  0.01361084 -0.02722168 -0.2109375   0.07177734  0.08691406\n",
      " -0.09960938  0.01422119 -0.18261719  0.00741577  0.01965332  0.00738525\n",
      " -0.03271484 -0.15234375 -0.26367188 -0.14746094  0.03320312 -0.03344727\n",
      " -0.01000977  0.01855469  0.00183868 -0.10498047  0.09667969  0.07910156\n",
      "  0.11181641  0.13085938 -0.08740234 -0.1328125   0.05004883  0.19824219\n",
      "  0.0612793   0.16210938  0.06933594  0.01281738  0.01550293  0.01531982\n",
      "  0.11474609  0.02758789  0.13769531 -0.08349609  0.01123047 -0.20507812\n",
      " -0.12988281 -0.16699219  0.20410156 -0.03588867 -0.10888672  0.0534668\n",
      "  0.15820312 -0.20410156  0.14648438 -0.11572266  0.01855469 -0.13574219\n",
      "  0.24121094  0.12304688 -0.14550781  0.17578125  0.11816406 -0.30859375\n",
      "  0.10888672 -0.22363281  0.19335938 -0.15722656 -0.07666016 -0.09082031\n",
      " -0.19628906 -0.23144531 -0.09130859 -0.14160156  0.06347656  0.03344727\n",
      " -0.03369141  0.06591797  0.06201172  0.3046875   0.16796875 -0.11035156\n",
      " -0.03833008 -0.02563477 -0.09765625  0.04467773 -0.0534668   0.11621094\n",
      " -0.15039062 -0.16308594 -0.15527344  0.04638672  0.11572266 -0.06640625\n",
      " -0.04516602  0.02331543 -0.08105469 -0.0255127  -0.07714844  0.0016861\n",
      "  0.15820312  0.00994873 -0.06445312  0.15722656 -0.03112793  0.10644531\n",
      " -0.140625    0.23535156 -0.11279297  0.16015625  0.00061798 -0.1484375\n",
      "  0.02307129 -0.109375    0.05444336 -0.14160156  0.11621094  0.03710938\n",
      "  0.14746094 -0.04199219 -0.01391602 -0.03881836  0.02783203  0.10205078\n",
      "  0.07470703  0.20898438 -0.04223633 -0.04150391 -0.00588989 -0.14941406\n",
      " -0.04296875 -0.10107422 -0.06176758  0.09472656  0.22265625 -0.02307129\n",
      "  0.04858398 -0.15527344 -0.02282715 -0.04174805  0.16699219 -0.09423828\n",
      "  0.14453125  0.11132812  0.04223633 -0.16699219  0.10253906  0.16796875\n",
      "  0.12597656 -0.11865234 -0.0213623  -0.08056641  0.24316406  0.15527344\n",
      "  0.16503906  0.00854492 -0.12255859  0.08691406 -0.11914062 -0.02941895\n",
      "  0.08349609 -0.03100586  0.13964844 -0.05151367  0.00765991 -0.04443359\n",
      " -0.04980469 -0.03222656 -0.00952148 -0.10888672 -0.10302734 -0.15722656\n",
      "  0.19335938  0.04858398  0.015625   -0.08105469 -0.11621094 -0.01989746\n",
      "  0.05737305  0.06103516 -0.14550781  0.06738281 -0.24414062 -0.07714844\n",
      "  0.04760742 -0.07519531 -0.14941406 -0.04418945  0.09716797  0.06738281]\n"
     ]
    }
   ],
   "source": [
    "countryVector = word_embeddings['country'] # Get the vector representation for the word 'country'\n",
    "# Print the type of the vector. Note it is a numpy array\n",
    "print(type(countryVector)) \n",
    "# Print the values of the vector.  \n",
    "print(countryVector) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06f06494-0ebe-4100-9bc4-f919542e08e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimensions=300\n"
     ]
    }
   ],
   "source": [
    "# Get the number of dimensions\n",
    "dimensions = countryVector.shape[0]\n",
    "print(f'{dimensions=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e43a8cc-9017-48e4-86db-e6ad95f15ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <td>-0.080078</td>\n",
       "      <td>0.133789</td>\n",
       "      <td>0.143555</td>\n",
       "      <td>0.094727</td>\n",
       "      <td>-0.047363</td>\n",
       "      <td>-0.023560</td>\n",
       "      <td>-0.008545</td>\n",
       "      <td>-0.186523</td>\n",
       "      <td>0.045898</td>\n",
       "      <td>-0.081543</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.145508</td>\n",
       "      <td>0.067383</td>\n",
       "      <td>-0.244141</td>\n",
       "      <td>-0.077148</td>\n",
       "      <td>0.047607</td>\n",
       "      <td>-0.075195</td>\n",
       "      <td>-0.149414</td>\n",
       "      <td>-0.044189</td>\n",
       "      <td>0.097168</td>\n",
       "      <td>0.067383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city</th>\n",
       "      <td>-0.010071</td>\n",
       "      <td>0.057373</td>\n",
       "      <td>0.183594</td>\n",
       "      <td>-0.040039</td>\n",
       "      <td>-0.029785</td>\n",
       "      <td>-0.079102</td>\n",
       "      <td>0.071777</td>\n",
       "      <td>0.013306</td>\n",
       "      <td>-0.143555</td>\n",
       "      <td>0.011292</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024292</td>\n",
       "      <td>-0.168945</td>\n",
       "      <td>-0.062988</td>\n",
       "      <td>0.117188</td>\n",
       "      <td>-0.020508</td>\n",
       "      <td>0.030273</td>\n",
       "      <td>-0.247070</td>\n",
       "      <td>-0.122559</td>\n",
       "      <td>0.076172</td>\n",
       "      <td>-0.234375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>China</th>\n",
       "      <td>-0.073242</td>\n",
       "      <td>0.135742</td>\n",
       "      <td>0.108887</td>\n",
       "      <td>0.083008</td>\n",
       "      <td>-0.127930</td>\n",
       "      <td>-0.227539</td>\n",
       "      <td>0.151367</td>\n",
       "      <td>-0.045654</td>\n",
       "      <td>-0.065430</td>\n",
       "      <td>0.034424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140625</td>\n",
       "      <td>0.087402</td>\n",
       "      <td>0.152344</td>\n",
       "      <td>0.079590</td>\n",
       "      <td>0.006348</td>\n",
       "      <td>-0.037842</td>\n",
       "      <td>-0.183594</td>\n",
       "      <td>0.137695</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>-0.079590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iraq</th>\n",
       "      <td>0.191406</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>-0.065430</td>\n",
       "      <td>0.060059</td>\n",
       "      <td>-0.285156</td>\n",
       "      <td>-0.102539</td>\n",
       "      <td>0.117188</td>\n",
       "      <td>-0.351562</td>\n",
       "      <td>-0.095215</td>\n",
       "      <td>0.200195</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.100586</td>\n",
       "      <td>-0.077148</td>\n",
       "      <td>-0.123047</td>\n",
       "      <td>0.193359</td>\n",
       "      <td>-0.153320</td>\n",
       "      <td>0.089355</td>\n",
       "      <td>-0.173828</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>0.302734</td>\n",
       "      <td>0.105957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oil</th>\n",
       "      <td>-0.139648</td>\n",
       "      <td>0.062256</td>\n",
       "      <td>-0.279297</td>\n",
       "      <td>0.063965</td>\n",
       "      <td>0.044434</td>\n",
       "      <td>-0.154297</td>\n",
       "      <td>-0.184570</td>\n",
       "      <td>-0.498047</td>\n",
       "      <td>0.047363</td>\n",
       "      <td>0.110840</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.195312</td>\n",
       "      <td>-0.345703</td>\n",
       "      <td>0.217773</td>\n",
       "      <td>-0.091797</td>\n",
       "      <td>0.051025</td>\n",
       "      <td>0.061279</td>\n",
       "      <td>0.194336</td>\n",
       "      <td>0.204102</td>\n",
       "      <td>0.235352</td>\n",
       "      <td>-0.051025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Belmopan</th>\n",
       "      <td>-0.265625</td>\n",
       "      <td>-0.380859</td>\n",
       "      <td>-0.049072</td>\n",
       "      <td>0.155273</td>\n",
       "      <td>-0.044922</td>\n",
       "      <td>-0.248047</td>\n",
       "      <td>-0.010376</td>\n",
       "      <td>-0.105957</td>\n",
       "      <td>-0.328125</td>\n",
       "      <td>0.119629</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047119</td>\n",
       "      <td>-0.034424</td>\n",
       "      <td>-0.005219</td>\n",
       "      <td>-0.265625</td>\n",
       "      <td>0.094727</td>\n",
       "      <td>0.170898</td>\n",
       "      <td>-0.353516</td>\n",
       "      <td>0.072754</td>\n",
       "      <td>-0.042969</td>\n",
       "      <td>0.229492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vaduz</th>\n",
       "      <td>0.324219</td>\n",
       "      <td>-0.056885</td>\n",
       "      <td>0.031494</td>\n",
       "      <td>-0.045898</td>\n",
       "      <td>0.042969</td>\n",
       "      <td>-0.062256</td>\n",
       "      <td>0.004089</td>\n",
       "      <td>-0.328125</td>\n",
       "      <td>-0.151367</td>\n",
       "      <td>0.242188</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.134766</td>\n",
       "      <td>-0.226562</td>\n",
       "      <td>-0.083496</td>\n",
       "      <td>-0.152344</td>\n",
       "      <td>-0.179688</td>\n",
       "      <td>0.205078</td>\n",
       "      <td>-0.016968</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.152344</td>\n",
       "      <td>0.027710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Paramaribo</th>\n",
       "      <td>-0.235352</td>\n",
       "      <td>-0.063477</td>\n",
       "      <td>0.154297</td>\n",
       "      <td>0.081055</td>\n",
       "      <td>-0.002716</td>\n",
       "      <td>-0.126953</td>\n",
       "      <td>-0.443359</td>\n",
       "      <td>-0.218750</td>\n",
       "      <td>0.038574</td>\n",
       "      <td>-0.063965</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.318359</td>\n",
       "      <td>-0.187500</td>\n",
       "      <td>0.304688</td>\n",
       "      <td>-0.192383</td>\n",
       "      <td>0.050781</td>\n",
       "      <td>0.234375</td>\n",
       "      <td>-0.341797</td>\n",
       "      <td>-0.100098</td>\n",
       "      <td>0.183594</td>\n",
       "      <td>-0.128906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nuuk</th>\n",
       "      <td>-0.318359</td>\n",
       "      <td>-0.546875</td>\n",
       "      <td>0.085449</td>\n",
       "      <td>-0.167969</td>\n",
       "      <td>-0.376953</td>\n",
       "      <td>-0.453125</td>\n",
       "      <td>-0.332031</td>\n",
       "      <td>-0.447266</td>\n",
       "      <td>-0.105469</td>\n",
       "      <td>-0.024780</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094727</td>\n",
       "      <td>-0.021484</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>-0.294922</td>\n",
       "      <td>-0.226562</td>\n",
       "      <td>0.084473</td>\n",
       "      <td>-0.104980</td>\n",
       "      <td>0.114746</td>\n",
       "      <td>0.163086</td>\n",
       "      <td>-0.225586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Funafuti</th>\n",
       "      <td>0.087402</td>\n",
       "      <td>0.158203</td>\n",
       "      <td>0.028320</td>\n",
       "      <td>-0.183594</td>\n",
       "      <td>-0.046631</td>\n",
       "      <td>-0.277344</td>\n",
       "      <td>-0.285156</td>\n",
       "      <td>-0.160156</td>\n",
       "      <td>0.064453</td>\n",
       "      <td>0.229492</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.223633</td>\n",
       "      <td>0.061279</td>\n",
       "      <td>0.098145</td>\n",
       "      <td>-0.158203</td>\n",
       "      <td>-0.056885</td>\n",
       "      <td>0.235352</td>\n",
       "      <td>-0.337891</td>\n",
       "      <td>0.057861</td>\n",
       "      <td>-0.030029</td>\n",
       "      <td>0.241211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>243 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0         1         2         3         4         5    \\\n",
       "country    -0.080078  0.133789  0.143555  0.094727 -0.047363 -0.023560   \n",
       "city       -0.010071  0.057373  0.183594 -0.040039 -0.029785 -0.079102   \n",
       "China      -0.073242  0.135742  0.108887  0.083008 -0.127930 -0.227539   \n",
       "Iraq        0.191406  0.125000 -0.065430  0.060059 -0.285156 -0.102539   \n",
       "oil        -0.139648  0.062256 -0.279297  0.063965  0.044434 -0.154297   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "Belmopan   -0.265625 -0.380859 -0.049072  0.155273 -0.044922 -0.248047   \n",
       "Vaduz       0.324219 -0.056885  0.031494 -0.045898  0.042969 -0.062256   \n",
       "Paramaribo -0.235352 -0.063477  0.154297  0.081055 -0.002716 -0.126953   \n",
       "Nuuk       -0.318359 -0.546875  0.085449 -0.167969 -0.376953 -0.453125   \n",
       "Funafuti    0.087402  0.158203  0.028320 -0.183594 -0.046631 -0.277344   \n",
       "\n",
       "                 6         7         8         9    ...       290       291  \\\n",
       "country    -0.008545 -0.186523  0.045898 -0.081543  ... -0.145508  0.067383   \n",
       "city        0.071777  0.013306 -0.143555  0.011292  ...  0.024292 -0.168945   \n",
       "China       0.151367 -0.045654 -0.065430  0.034424  ...  0.140625  0.087402   \n",
       "Iraq        0.117188 -0.351562 -0.095215  0.200195  ... -0.100586 -0.077148   \n",
       "oil        -0.184570 -0.498047  0.047363  0.110840  ... -0.195312 -0.345703   \n",
       "...              ...       ...       ...       ...  ...       ...       ...   \n",
       "Belmopan   -0.010376 -0.105957 -0.328125  0.119629  ...  0.047119 -0.034424   \n",
       "Vaduz       0.004089 -0.328125 -0.151367  0.242188  ... -0.134766 -0.226562   \n",
       "Paramaribo -0.443359 -0.218750  0.038574 -0.063965  ... -0.318359 -0.187500   \n",
       "Nuuk       -0.332031 -0.447266 -0.105469 -0.024780  ...  0.094727 -0.021484   \n",
       "Funafuti   -0.285156 -0.160156  0.064453  0.229492  ... -0.223633  0.061279   \n",
       "\n",
       "                 292       293       294       295       296       297  \\\n",
       "country    -0.244141 -0.077148  0.047607 -0.075195 -0.149414 -0.044189   \n",
       "city       -0.062988  0.117188 -0.020508  0.030273 -0.247070 -0.122559   \n",
       "China       0.152344  0.079590  0.006348 -0.037842 -0.183594  0.137695   \n",
       "Iraq       -0.123047  0.193359 -0.153320  0.089355 -0.173828 -0.054688   \n",
       "oil         0.217773 -0.091797  0.051025  0.061279  0.194336  0.204102   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "Belmopan   -0.005219 -0.265625  0.094727  0.170898 -0.353516  0.072754   \n",
       "Vaduz      -0.083496 -0.152344 -0.179688  0.205078 -0.016968  0.156250   \n",
       "Paramaribo  0.304688 -0.192383  0.050781  0.234375 -0.341797 -0.100098   \n",
       "Nuuk        0.009766 -0.294922 -0.226562  0.084473 -0.104980  0.114746   \n",
       "Funafuti    0.098145 -0.158203 -0.056885  0.235352 -0.337891  0.057861   \n",
       "\n",
       "                 298       299  \n",
       "country     0.097168  0.067383  \n",
       "city        0.076172 -0.234375  \n",
       "China       0.093750 -0.079590  \n",
       "Iraq        0.302734  0.105957  \n",
       "oil         0.235352 -0.051025  \n",
       "...              ...       ...  \n",
       "Belmopan   -0.042969  0.229492  \n",
       "Vaduz       0.152344  0.027710  \n",
       "Paramaribo  0.183594 -0.128906  \n",
       "Nuuk        0.163086 -0.225586  \n",
       "Funafuti   -0.030029  0.241211  \n",
       "\n",
       "[243 rows x 300 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframes can be more practical to view and and manipulate data\n",
    "df_embeds = pd.DataFrame(word_embeddings)\n",
    "df_embeds.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4b0271-29ef-425b-aef1-4e50e8a55688",
   "metadata": {},
   "source": [
    "## Predicting relationships between words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91635068-aad0-4cef-adac-317a34fd2603",
   "metadata": {},
   "source": [
    "You will now write a function that can help predict a word given a relationship between two initial words :\n",
    "\n",
    "* The function will take as input three words.\n",
    "* The first two are related to each other.\n",
    "* It will predict a 4th word which is related to the third word, in a manner similar to the one we can imply from the first 2 words.\n",
    "* As an example, \"Italy is to Rome what France is to __\"?\n",
    "* You will write a program that is capable of finding the fourth word.\n",
    "* This will be applied to finding the countries of capitals.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf91da8f-053a-49da-a461-1c612a6cf7b3",
   "metadata": {},
   "source": [
    "To do this, first write functions to compute the cosine similarity metric or the Euclidean distance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6229630f-bacb-4b0e-903f-c66e5a44ceab",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af7b312-a0ad-4ed5-9399-ab19e0626995",
   "metadata": {},
   "source": [
    "Cosine similarity is defined as :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5df5136-0850-45a1-9ab1-ed1d786d707c",
   "metadata": {},
   "source": [
    "$$ simil(\\mathbf{a,b}) = cos \\theta = \\frac{\\mathbf a \\cdot \\mathbf b}{\\Vert \\mathbf a \\Vert \\times \\lVert \\mathbf b \\rVert}$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414f2551-5f60-4662-8df6-b17cf485dc79",
   "metadata": {},
   "source": [
    "And the Euclidian norm of a vector is defined as   \n",
    "\n",
    "$$ \\Vert \\bf a \\Vert = \\sqrt{\\sum_{i=1}^{n}{a_i^2}} $$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8416ed-ec45-4a01-a077-f44ba67adb78",
   "metadata": {},
   "source": [
    "**Implement a function that takes in 2 word vectors and computes their cosine similarity**  \n",
    "You may use `np.dot` to calculate the dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bae7fd5-084e-448e-915a-989173030758",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    \"\"\" \n",
    "    Input :\n",
    "    a : a numpy array representing word a as a vector\n",
    "    b : a numpy array representing word b as a vector\n",
    "    \n",
    "    Output:\n",
    "    cos_ab : a scalar proportional to the the similarity in angles between a and b\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    dot_ab = np.dot(a,b)\n",
    "    norm_a = np.sqrt(np.sum(a**2))\n",
    "    norm_b = np.sqrt(np.sum(b**2))\n",
    "    \n",
    "    # compute cos\n",
    "    cos_ab = dot_ab/(norm_a*norm_b)\n",
    "    \n",
    "    # output\n",
    "    return cos_ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d581302d-a1b0-488d-9b4b-cc6b63970214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6510956"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the function\n",
    "king = word_embeddings['king']\n",
    "queen = word_embeddings['queen']\n",
    "\n",
    "cosine_similarity(king, queen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6586423f-61df-4a56-8812-d96ff74be446",
   "metadata": {},
   "source": [
    "**Expected Out**  \n",
    "0.6510956"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6206cabc-a6aa-4475-8eec-82b4321ebaf4",
   "metadata": {},
   "source": [
    "### 2. Euclidian Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c09bd6-5f23-4365-bff4-1392999ea49b",
   "metadata": {},
   "source": [
    "Using the formula above, write a funciton which computes the euclidian distance bewteen 2 word vectors.  \n",
    "**Hint**: you are looking for the norm of the vector which seperates the tips of 2 vectors..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d3deb23-6328-401a-b852-bb5c4ccc77f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean(a, b):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    a : a numpy array representing word a as a vector\n",
    "    b : a numpy array representing word b as a vector\n",
    "    \n",
    "    Output:\n",
    "    d: scalar representing the Euclidean distance between a and b\n",
    "    \"\"\"\n",
    "    \n",
    "    # the vector going from a to b\n",
    "    vec_a2b = b-a\n",
    "    \n",
    "    # norm of that vector / Euclidian distance bewteen a and b\n",
    "    d = np.linalg.norm(vec_a2b)\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27e54160-9dd5-4751-a005-28a71397e635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4796925"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test your function\n",
    "euclidean(king, queen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4964ce9-129d-49a0-93a7-f282121b2ad9",
   "metadata": {},
   "source": [
    "**Expected Out**  \n",
    "2.4796925"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a56e0b-1fa0-4028-89f2-0c04e7db8514",
   "metadata": {},
   "source": [
    "### 3. Finding the country of each capital"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95e9013-2303-4e3b-b2cf-0dbd7f8dcfab",
   "metadata": {},
   "source": [
    "Now, you can use the previous functions to compute similarities between vectors, and use these to find the capital cities of countries.  \n",
    "You will write a function that takes three words as input, and the embeddings dictionary. Your task is to find the correct capital city. For example, given the following words:\n",
    "\n",
    "* 1: Athens, 2: Greece, 3: Baghdad\n",
    "\n",
    "your task is to predict the country 4: Iraq."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c07e37d-7f55-4092-911d-5fc8d506b748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_country(city1, country1, city2, embeddings):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        city1: a string (the capital city of country1)\n",
    "        country1: a string (the country of capital1)\n",
    "        city2: a string (the capital city of country2)\n",
    "        embeddings: a dictionary where the keys are words and values are their embeddings\n",
    "        \n",
    "    Output:\n",
    "        countries: a dictionary with the most likely country and its similarity score\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # store the city1, country 1, and city 2 in a set called group\n",
    "    group = (city1,country1, city2)\n",
    "    \n",
    "    # get their embeddings\n",
    "    city1_emb = embeddings[city1]\n",
    "    country1_emb = embeddings[country1]\n",
    "    city2_emb = embeddings[city2]\n",
    "    \n",
    "    # calculate the embedding of country2 using simple linear algebra\n",
    "    # Remember : king - man + woman = queen\n",
    "    vec = country1_emb - city1_emb + city2_emb\n",
    "    \n",
    "    \n",
    "    # Finding the closest word embedding :\n",
    "    \n",
    "    # loop through all the words in the embeddings dict, checking that it isnt in the group defined above and \n",
    "    # then calculate the similarity (using whichever metric you prefer).  If the similarity is higher, then write \n",
    "    # over the stored best_similarity and update country, which stores a tuple (country_name, similarity_score).\n",
    "    # Finally return the country tuple.\n",
    "    \n",
    "    \n",
    "    # Initialize the similarity to -1 (it will be replaced by a similarities that are closer to +1)\n",
    "    best_similarity = -1\n",
    "    \n",
    "    # initialize country to an empty string\n",
    "    country = ''\n",
    "    \n",
    "    # loop through all words in the embeddings dictionary\n",
    "    for word in embeddings.keys():\n",
    "        \n",
    "        #check word if not in group\n",
    "        if word not in group:\n",
    "        # get the embedding for the word\n",
    "            word_emb = embeddings[word]\n",
    "        # compute the similarity\n",
    "            similarity = cosine_similarity(vec, word_emb)\n",
    "        # if the similarity is higher\n",
    "            if similarity > best_similarity:\n",
    "            # update the best_similarity variable\n",
    "                best_similarity = similarity\n",
    "            # update the country variable with a tuple which contains the country and the similarity\n",
    "                country = (word, similarity)\n",
    "        \n",
    "    return country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cc9d5d2-f27b-464a-b9dc-86907b9ce8d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Egypt', 0.72618926)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test your function\n",
    "get_country('Paris', 'France', 'Cairo', word_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0365997b-85b3-4f84-a9a2-a5ec1a5b9d48",
   "metadata": {},
   "source": [
    "### 4. Model Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b16e160-76e9-47ad-9d3b-9d8bc5b89b16",
   "metadata": {},
   "source": [
    "Now you can test your new function on a dataset of capital/country pairs and check the accuracy of the model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e97a5f-f8e4-41f9-9412-cab75a0774d7",
   "metadata": {},
   "source": [
    "$$\\text{Accuracy}=\\frac{\\text{Correct # of predictions}}{\\text{Total # of predictions}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "313ee60f-1d48-41bd-a6f2-74ecc9d66f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city1</th>\n",
       "      <th>country1</th>\n",
       "      <th>city2</th>\n",
       "      <th>country2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Athens</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Bangkok</td>\n",
       "      <td>Thailand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Athens</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>China</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Athens</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Athens</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Bern</td>\n",
       "      <td>Switzerland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Athens</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Cairo</td>\n",
       "      <td>Egypt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    city1 country1    city2     country2\n",
       "0  Athens   Greece  Bangkok     Thailand\n",
       "1  Athens   Greece  Beijing        China\n",
       "2  Athens   Greece   Berlin      Germany\n",
       "3  Athens   Greece     Bern  Switzerland\n",
       "4  Athens   Greece    Cairo        Egypt"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data file\n",
    "data = pd.read_csv('capitals.txt', delimiter=' ')\n",
    "# name columns\n",
    "data.columns = ['city1', 'country1', 'city2', 'country2']\n",
    "\n",
    "data.head() # print first 5 lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2806ceff-ab6a-4510-8ebb-ec5ffd0217ed",
   "metadata": {},
   "source": [
    "Write a program that can compute the accuracy on the dataset. You have to iterate over every row to get the corresponding words and feed them into your `get_country` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3348e029-e91f-49d9-ae3f-7e877860c6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(word_embeddings, data):\n",
    "    '''\n",
    "    Input:\n",
    "        word_embeddings: a dictionary where the key is a word and the value is its embedding\n",
    "        data: a pandas dataframe containing all the country and capital city pairs\n",
    "    \n",
    "    Output:\n",
    "        accuracy: the accuracy of the model\n",
    "    '''\n",
    "\n",
    "    # initialize num correct to zero\n",
    "    num_correct = 0\n",
    "\n",
    "    # loop through the rows of the dataframe\n",
    "    for i, row in data.iterrows():\n",
    "\n",
    "        # get city1\n",
    "        city1 = row['city1']\n",
    "\n",
    "        # get country1\n",
    "        country1 = row['country1']\n",
    "\n",
    "        # get city2\n",
    "        city2 =  row['city2']\n",
    "\n",
    "        # get country2\n",
    "        country2 = row['country2']\n",
    "\n",
    "        # use get_country to find the predicted country2\n",
    "        predicted_country2, _ = get_country(city1, country1, city2, word_embeddings)\n",
    "\n",
    "        # if the predicted country2 is the same as the actual country2...\n",
    "        if predicted_country2 == country2:\n",
    "            # increment the number of correct by 1\n",
    "            num_correct += 1\n",
    "\n",
    "    # get the number of rows in the data dataframe (length of dataframe)\n",
    "    m = len(data)\n",
    "\n",
    "    # calculate the accuracy by dividing the number correct by m\n",
    "    accuracy = num_correct/m\n",
    "\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5d34fb0-80f8-419e-a926-7d8f604a9ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.919\n"
     ]
    }
   ],
   "source": [
    "# compute accuracy\n",
    "accuracy = get_accuracy(word_embeddings, data)\n",
    "print(f\"Accuracy is {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e1c4c4-de7e-4e42-82ee-1c16d952848e",
   "metadata": {},
   "source": [
    "**Expected Out**  \n",
    "0.92"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
