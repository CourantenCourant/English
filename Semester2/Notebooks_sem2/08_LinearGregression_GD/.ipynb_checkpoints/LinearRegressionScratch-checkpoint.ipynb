{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3c94dcf-c3b3-4015-92b1-59836cee410a",
   "metadata": {},
   "source": [
    "# Single Variable (Univariate) Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd03a7be-d861-48bb-9e06-5e86e001c3ae",
   "metadata": {},
   "source": [
    "Using the toy dataset loaded below, the goal is to write the linear regression algorithm with Gradient Descent from scratch ! This will help you familiarize yourselves with the essential steps of most machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74dd827-39c2-40f7-95c9-bf74ca095b86",
   "metadata": {},
   "source": [
    "## The Data\n",
    "This is a toy dataset of 100 examples, where the lot area is in m2 and the sale price is in thousands.  The sale prices have been divided by a factor of thousand to have features and labels on a similar scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92cf68b2-b28e-466f-9779-0dae5aa12882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32.502345</td>\n",
       "      <td>31.707006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53.426804</td>\n",
       "      <td>68.777596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61.530358</td>\n",
       "      <td>62.562382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47.475640</td>\n",
       "      <td>71.546632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59.813208</td>\n",
       "      <td>87.230925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     LotArea  SalePrice\n",
       "0  32.502345  31.707006\n",
       "1  53.426804  68.777596\n",
       "2  61.530358  62.562382\n",
       "3  47.475640  71.546632\n",
       "4  59.813208  87.230925"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Preprocessing Input data\n",
    "data = pd.read_csv('data.csv', names=['LotArea', 'SalePrice'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e52173f-66c3-415d-be51-bbbf6064a46e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = data.iloc[:, 0] \n",
    "labels = data.iloc[:, 1]\n",
    "plt.scatter(X, labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087defb1-e357-4a6b-b111-346afa2eb32e",
   "metadata": {},
   "source": [
    "## The model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cbb2e6-8694-4253-af93-adeb40fe659c",
   "metadata": {},
   "source": [
    "For single variable linear regression, our model is defined by the function:  \n",
    "$$h(x) = \\theta_0 + \\theta_1x$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f039293e-2a45-4679-a855-2b36d9ea64de",
   "metadata": {},
   "source": [
    "Write a function which returns an array of predictions, using as input :\n",
    "* an array of examples with a single feature\n",
    "* the parameters of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4accd0ae-2de1-4e59-b348-aa5bff7ab368",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, theta0, theta1):\n",
    "    \n",
    "    # transcribe the formula above, easy enough :\n",
    "    preds = None\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c190b280-ffcd-418a-9baa-08611e50c246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you should have an array of predictions\n",
    "predict(X, theta0=1, theta1=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fb0583-29a4-4379-b275-5e1810f42521",
   "metadata": {},
   "source": [
    "**Expected output for the first example is 54.43**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84585d22-4808-4c65-9351-8c1a436a93ac",
   "metadata": {},
   "source": [
    "## The Cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce61442-4c03-442d-b1bd-6c1eb151aef7",
   "metadata": {},
   "source": [
    "The cost function allows you to evaluate how good your model fits the data.  In this case, we are going to use the MSE (Mean Squared Error) loss, defined as :\n",
    "$$ J(\\theta_0, \\theta_1) = \\frac{1}{2m}\\sum_{i=1}^m (h(x^i) - y^i)^2 $$ \n",
    "\n",
    "where *m* is the number of examples, so 100 in our case.\n",
    "\n",
    "This gives us the average error over our model's predictions.  Write a function which outputs this cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c97eaaf0-c830-437a-90a1-fdd3b3000425",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(preds, labels):\n",
    "    \"\"\"\n",
    "    Preds and labels are numpy arrays, so no need to use \"for\" loops !\n",
    "    Try doing some of the operations on paper with numpy arrays of only 2-3 examples to make things easier.\n",
    "    \"\"\"\n",
    "    # length of the dataset\n",
    "    m = None\n",
    "    \n",
    "    # write out the formula above without using a for loop to go through each elment of the predictions array.\n",
    "    \n",
    "    # predictions - labels => the array of differences\n",
    "    differences = None\n",
    "    \n",
    "    # Square the differences\n",
    "    diff_squared = None\n",
    "    \n",
    "    # Sum the squared differences and divide by 2m :\n",
    "    loss = None\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49b1f982-a55f-4702-aa82-8fcd20ae31e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test your function\n",
    "cost(labels+1, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74b2653-8d1c-4b1f-aa76-37885bdaf504",
   "metadata": {},
   "source": [
    "**Expected output is 0.5**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b1ec25-2f16-4b56-814d-8c24d4ddd140",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a807f77-938c-4bfd-a809-f67974b1fad5",
   "metadata": {},
   "source": [
    "Gradient Descent performs updates on the weights of the model, in order to minimize the cost/loss (these can be used interchangeably).  \n",
    "Here is the formula for the update of each parameter in the model :\n",
    "$$ \\theta_0 = \\theta_0 - \\alpha  \\frac{1}{m} \\sum_{i=1}^{m}(h(x^i) - y^i) $$\n",
    "$$ \\theta_1 = \\theta_1 - \\alpha  \\frac{1}{m} \\sum_{i=1}^{m}(h(x^i) - y^i)x^i$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41544ca5-e98c-4357-bf0a-545ea3115130",
   "metadata": {},
   "source": [
    "Where *alpha* is the `learning_rate` (the size of the update steps we want to take) and the term on the right is the formula for the partial derivative of the cost function, with respect to each parameter.\n",
    "Write a function which performs these updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f568668-ee87-4a61-afa5-8de2a7808a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(learning_rate, X, preds, labels, theta0, theta1):\n",
    "    \n",
    "    # write out the part of the formula which comes right after alpha, the partial derivatives :\n",
    "    \n",
    "    # difference preds/labels\n",
    "    difference = None\n",
    "\n",
    "    \n",
    "    # for theta 1, each difference int he array of differences needs to be multiplied by its example x :\n",
    "    difference_X = None\n",
    "    \n",
    "    # all that's left is applying the mean (sum/m) to get the partial derivatives of each parameter :\n",
    "    partial_theta0 = None\n",
    "    \n",
    "    partial_theta1 = None\n",
    "    \n",
    "    \n",
    "    # update the parameters!\n",
    "    theta0 -= None\n",
    "    theta1 -= None\n",
    "    \n",
    "    return theta0, theta1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071b3a48-010f-4517-955f-0248b33223f6",
   "metadata": {},
   "source": [
    "## Main Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377e0267-786a-4408-bfcc-d758e0777be8",
   "metadata": {},
   "source": [
    "We can now go through the data and fit our model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49f80008-93ba-4747-ab73-c6f5a119f492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must be the same size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# plot the model to have a visual intuition of the model's progress\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot([\u001b[38;5;28mmin\u001b[39m(X), \u001b[38;5;28mmax\u001b[39m(X)], [\u001b[38;5;28mmin\u001b[39m(Y_pred), \u001b[38;5;28mmax\u001b[39m(Y_pred)], color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# predicted\u001b[39;00m\n\u001b[1;32m     29\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/miniconda3/envs/ML/lib/python3.9/site-packages/matplotlib/pyplot.py:2807\u001b[0m, in \u001b[0;36mscatter\u001b[0;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, data, **kwargs)\u001b[0m\n\u001b[1;32m   2802\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mscatter)\n\u001b[1;32m   2803\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscatter\u001b[39m(\n\u001b[1;32m   2804\u001b[0m         x, y, s\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, c\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2805\u001b[0m         vmin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, vmax\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, linewidths\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   2806\u001b[0m         edgecolors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, plotnonfinite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 2807\u001b[0m     __ret \u001b[38;5;241m=\u001b[39m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscatter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2808\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmarker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmarker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcmap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2809\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvmax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlinewidths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlinewidths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2810\u001b[0m \u001b[43m        \u001b[49m\u001b[43medgecolors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medgecolors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplotnonfinite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplotnonfinite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2811\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2812\u001b[0m     sci(__ret)\n\u001b[1;32m   2813\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m __ret\n",
      "File \u001b[0;32m~/miniconda3/envs/ML/lib/python3.9/site-packages/matplotlib/__init__.py:1412\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1409\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m   1410\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1411\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1412\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1414\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1415\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[1;32m   1416\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m~/miniconda3/envs/ML/lib/python3.9/site-packages/matplotlib/axes/_axes.py:4323\u001b[0m, in \u001b[0;36mAxes.scatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[1;32m   4321\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mma\u001b[38;5;241m.\u001b[39mravel(y)\n\u001b[1;32m   4322\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39msize:\n\u001b[0;32m-> 4323\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must be the same size\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   4325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m s \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4326\u001b[0m     s \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m20\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m rcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_internal.classic_mode\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[1;32m   4327\u001b[0m          rcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlines.markersize\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2.0\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must be the same size"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Choose the \"hyperparameters\" you want :\n",
    "# The learning rate, typically very low, between 1e-2 and 1e-6 depending on the task.  \n",
    "# 1e-4 is recommended to begin with in this case\n",
    "LR = 1e-4  \n",
    "# The number of passes over the dataset, ie. the number of times we update the weights.  These are alled \"epochs\".\n",
    "EPOCHS = 10  \n",
    "\n",
    "m = len(X) # Number of elements in X\n",
    "\n",
    "\n",
    "# Initilize the cost/loss to a very high value\n",
    "prev_loss = 1e9\n",
    "# Initialize the parameters, setting them to random values between 0 and 1:\n",
    "theta0, theta1 = random.random(), random.random()\n",
    "\n",
    "\n",
    "# Loop\n",
    "for i in range(EPOCHS): \n",
    "       \n",
    "    # compute the model's predictions\n",
    "    Y_pred = None\n",
    "    \n",
    "    # plot the model to have a visual intuition of the model's progress\n",
    "    print(f'epoch {i}')\n",
    "    plt.scatter(X, labels)\n",
    "    plt.plot([min(X), max(X)], [min(Y_pred), max(Y_pred)], color='red') # predicted\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    # compute the loss\n",
    "    loss = None\n",
    "    print(f'Loss = {loss}')\n",
    "    \n",
    "    # To see if the model is improving, compare this loss to the previous loss.\n",
    "    # if the difference is smaller than 1e-2, then we can consider the model has found the global minimum \n",
    "    # and there is no need to continue updating the weights.\n",
    "    \n",
    "    # if previous los - loss is smaller than 1e-2 :\n",
    "        \n",
    "        # break the for loop\n",
    "        \n",
    "    # if the difference is significant, update the previous loss\n",
    "    prev_loss = None\n",
    "                     \n",
    "    \n",
    "    # and update the parameters  \n",
    "    theta0, theta1 = None\n",
    "\n",
    "print(f'{theta0=}, {theta1=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f608b1-e181-4641-8f78-6c2d6d8fcd24",
   "metadata": {},
   "source": [
    "**Expected values** for theta0 and theta1 should be \n",
    "* theta0 => between 0 and 1\n",
    "* theta1 => close to 1.47"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d328454-e976-448a-9961-9fde3d4b8b6a",
   "metadata": {},
   "source": [
    "Play around with the learning rates !! Set 10 epochs and comment out the condition with the break statement beforehand and then try:\n",
    "* 5e-4 : how many epochs til the loss stops changing ?\n",
    "* 1e-2 : what's going on with the model ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1aa2698-6668-4161-b7ec-97d6f561a7f5",
   "metadata": {},
   "source": [
    "# Multivariate Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12250e33-3e17-4eda-9af6-caafe13db14e",
   "metadata": {},
   "source": [
    "You make look through this, but we will go through it together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f1ec952-c68a-4299-a7a7-745698e86793",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a toy dataset\n",
    "\n",
    "X = np.random.randn(5, 500) # 5 features, 500 examples\n",
    "y = 3 * X[0, :] + np.random.randn(1, 500) * 0.1 # to vreate the labels, take the first row of X and add noise => *3, add random numbers*0.1\n",
    "\n",
    "\n",
    "X1 = np.ones((1, X.shape[1]))\n",
    "X = np.append(X, X1, axis=0) # add \"dummy\" features as a row of ones\n",
    "#print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1dbf2af3-c5bf-404e-88d9-f28f0c983839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m => number of examples\n",
    "# n => number of features\n",
    "m = X.shape[1]\n",
    "n = X.shape[0]\n",
    "\n",
    "# initialize parameter/weight vector\n",
    "theta = np.random.randn(n, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef9a6a94-8d22-4581-a665-492f96ebd8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is 7.6505861788921745 at epoch 0\n",
      "Loss is 0.005016593387225809 at epoch 2000\n",
      "Loss is 0.005016593387213702 at epoch 4000\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-2\n",
    "epochs = 5000\n",
    "\n",
    "for epoch in range(epochs+1):\n",
    "    preds = np.dot(theta.reshape(1,-1), X)\n",
    "    loss = np.mean((preds - y)**2) / 2\n",
    "    #print(f'Loss : {loss}')\n",
    "    if epoch % 2000 == 0: \n",
    "        print(f'Loss is {loss} at epoch {epoch}')\n",
    "    \n",
    "    dL_dtheta = 1/m * np.dot(X, (preds-y).T)\n",
    "    theta -= lr * dL_dtheta\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
